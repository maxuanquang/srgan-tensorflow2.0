{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy, multiprocessing\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import tensorlayer as tl\n",
    "from model import get_G, get_D\n",
    "from config import config\n",
    "import cv2\n",
    "from imutils.paths import list_images\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] [!] samples exists ...\n",
      "[TL] [!] models exists ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###====================== HYPER-PARAMETERS ===========================###\n",
    "## Adam\n",
    "batch_size = config.TRAIN.batch_size  # use 8 if your GPU memory is small, and change [4, 4] in tl.vis.save_images to [2, 4]\n",
    "lr_init = config.TRAIN.lr_init\n",
    "beta1 = config.TRAIN.beta1\n",
    "\n",
    "## initialize G - khoi dong G\n",
    "n_epoch_init = config.TRAIN.n_epoch_init\n",
    "number_of_images = config.TRAIN.number_of_images\n",
    "input_G_shape = config.TRAIN.input_G_shape\n",
    "input_D_shape = config.TRAIN.input_D_shape\n",
    "verbose = config.TRAIN.verbose\n",
    "n_epochs_save_model = config.TRAIN.n_epochs_save_model\n",
    "g_trained_dir = config.TRAIN.g_trained_dir\n",
    "d_trained_dir = config.TRAIN.d_trained_dir\n",
    "g_warmed_up_dir = config.TRAIN.g_warmed_up_dir\n",
    "\n",
    "g_losses_txt = config.TRAIN.g_losses_txt\n",
    "d_losses_txt = config.TRAIN.d_losses_txt\n",
    "\n",
    "## adversarial learning (SRGAN)\n",
    "n_epoch = config.TRAIN.n_epoch\n",
    "lr_decay = config.TRAIN.lr_decay\n",
    "decay_every = config.TRAIN.decay_every\n",
    "shuffle_buffer_size = config.TRAIN.shuffle_buffer_size\n",
    "\n",
    "# ni = int(np.sqrt(batch_size))\n",
    "\n",
    "# create folders to save result images and trained models\n",
    "save_dir = config.SAVE_DIR\n",
    "tl.files.exists_or_mkdir(save_dir)\n",
    "checkpoint_dir = config.CHECKPOINT_DIR\n",
    "tl.files.exists_or_mkdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data():    \n",
    "    train_hr_img_list = tl.files.load_file_list(path=config.TRAIN.hr_img_path, regx='.*.png', printable=False)[:number_of_images]\n",
    "    train_hr_imgs = tl.vis.read_images(train_hr_img_list, path=config.TRAIN.hr_img_path, n_threads=32)\n",
    "    # (1356, 2040, 3)\n",
    "    def generator_train():\n",
    "        for img in train_hr_imgs:\n",
    "            yield img\n",
    "    \n",
    "    def _map_fn_train(img):\n",
    "        hr_patch = tf.image.random_crop(img, input_D_shape)\n",
    "        # chuyen phan bo ve -1 +1\n",
    "        hr_patch = hr_patch/(255./2.)\n",
    "        hr_patch = hr_patch - 1.\n",
    "        hr_patch = tf.image.random_flip_left_right(hr_patch)\n",
    "        lr_patch = tf.image.resize(hr_patch, size=input_G_shape[:2])\n",
    "        return lr_patch, hr_patch\n",
    "\n",
    "    train_ds = tf.data.Dataset.from_generator(generator_train, output_types=(tf.float32))\n",
    "    train_ds = train_ds.map(_map_fn_train, num_parallel_calls=multiprocessing.cpu_count())\n",
    "    train_ds = train_ds.shuffle(shuffle_buffer_size)\n",
    "    train_ds = train_ds.batch(batch_size)\n",
    "    train_ds = train_ds.prefetch(buffer_size=2) # prefetch truoc 2 batch\n",
    "    return train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warmup():\n",
    "    '''\n",
    "    Warm-up G (Generator) using Mean Absolute Error Loss\n",
    "    '''\n",
    "    G = get_G(input_G_shape)\n",
    "\n",
    "    lr_v = tf.Variable(lr_init)\n",
    "    g_optimizer_init=tf.optimizers.Adam(lr_v, beta_1=beta1)\n",
    "\n",
    "    train_ds = get_train_data()\n",
    "    total_images = len(tl.files.load_file_list(path=config.TRAIN.hr_img_path, regx='.*.png', printable=False)[:number_of_images])\n",
    "    n_step_epoch = math.ceil(total_images / batch_size)\n",
    "\n",
    "    # initialize learning\n",
    "    for epoch in range(n_epoch_init):\n",
    "        for step,(lr_patchs,hr_patchs) in enumerate(train_ds):\n",
    "            step_time = time.time()\n",
    "            with tf.GradientTape() as tape:\n",
    "                fake_hr_patchs = G(lr_patchs)\n",
    "                mae_loss = tf.keras.losses.mean_absolute_error(fake_hr_patchs, hr_patchs)\n",
    "            grad = tape.gradient(mae_loss, G.trainable_weights)\n",
    "            g_optimizer_init.apply_gradients(zip(grad,G.trainable_weights))\n",
    "            if (step == 0) or ((step+1) % verbose == 0):\n",
    "                print(\"Epoch: [{}/{}] step: [{}/{}] time: {:.3f}s, mae: {:.3f} \".format(\n",
    "                    epoch+1, n_epoch_init, step+1, n_step_epoch, time.time() - step_time, np.mean(mae_loss)))\n",
    "        if (epoch!=0) and ((epoch+1)%n_epochs_save_model==0):\n",
    "            G.save_weights(os.path.join(checkpoint_dir, 'g_warmed_up_{}.h5'.format(epoch+1)))\n",
    "    G.save_weights(os.path.join(checkpoint_dir, 'g_warmed_up.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    G = get_G(input_G_shape)\n",
    "    G.load_weights(g_warmed_up_dir)\n",
    "    D = get_D(input_D_shape)\n",
    "\n",
    "    VGG = tf.keras.applications.VGG16(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_tensor=None,\n",
    "        input_shape=None,\n",
    "        pooling=max,\n",
    "        classes=2,\n",
    "    )\n",
    "    # Save architecture and weight\n",
    "    with open(os.path.join(checkpoint_dir, 'VGG.json'), 'w') as f:\n",
    "        f.write(VGG.to_json())\n",
    "    VGG.save_weights(os.path.join(checkpoint_dir, 'VGG.h5'))\n",
    "\n",
    "    lr_v = tf.Variable(lr_init)\n",
    "    g_optimizer=tf.optimizers.Adam(lr_v, beta_1=beta1)\n",
    "    d_optimizer=tf.optimizers.Adam(lr_v, beta_1=beta1)\n",
    "\n",
    "    train_ds = get_train_data()\n",
    "    total_images = len(tl.files.load_file_list(path=config.TRAIN.hr_img_path, regx='.*.png', printable=False)[:number_of_images])\n",
    "    n_step_epoch = math.ceil(total_images / batch_size)\n",
    "\n",
    "    # adversarial learning (G,D)\n",
    "    for epoch in range(n_epoch):\n",
    "        g_losses = []\n",
    "        d_losses = []\n",
    "        for step, (lr_patchs, hr_patchs) in enumerate(train_ds):\n",
    "            step_time = time.time()\n",
    "            # To compute multiple gradients over the same computation, create a persistent gradient tape\n",
    "            with tf.GradientTape(persistent=True) as tape:\n",
    "                fake_patchs = G(lr_patchs)\n",
    "                logits_fake = D(fake_patchs)\n",
    "                logits_real = D(hr_patchs)\n",
    "                feature_fake = VGG((fake_patchs+1)/2.) # the pre-trained VGG uses the input range of [0, 1] but we use input range of [-1 1]\n",
    "                feature_real = VGG((hr_patchs+1)/2.)\n",
    "\n",
    "                d_loss1 = tf.keras.losses.binary_crossentropy(tf.ones_like(logits_real),logits_real, from_logits=True)\n",
    "                d_loss2 = tf.keras.losses.binary_crossentropy(tf.zeros_like(logits_fake),logits_fake,from_logits=True)\n",
    "                d_loss1 = tf.reduce_mean(d_loss1)\n",
    "                d_loss2 = tf.reduce_mean(d_loss2)\n",
    "                d_loss = d_loss1 + d_loss2\n",
    "                g_gan_loss = tf.multiply(tf.constant(1e-3),tf.keras.losses.binary_crossentropy(tf.ones_like(logits_fake),logits_fake,from_logits=True))\n",
    "                g_gan_loss = tf.reduce_mean(g_gan_loss)\n",
    "                mse_loss = tf.keras.losses.mean_squared_error(fake_patchs, hr_patchs)\n",
    "                mse_loss = tf.reduce_mean(mse_loss)\n",
    "                vgg_loss = tf.multiply(tf.constant(2e-6),tf.keras.losses.mean_squared_error(feature_fake, feature_real))\n",
    "                vgg_loss = tf.reduce_mean(vgg_loss)\n",
    "                g_loss = mse_loss + vgg_loss + g_gan_loss\n",
    "            grad = tape.gradient(g_loss, G.trainable_weights)\n",
    "            g_optimizer.apply_gradients(zip(grad, G.trainable_weights))\n",
    "            grad = tape.gradient(d_loss, D.trainable_weights)\n",
    "            d_optimizer.apply_gradients(zip(grad, D.trainable_weights))\n",
    "            if (step == 0) or ((step+1) % verbose == 0):\n",
    "                print(\"Epoch: [{}/{}] step: [{}/{}] time: {:.3f}s, g_loss(mse:{:.3f}, vgg:{:.3f}, adv:{:.3f}) d_loss: {:.3f} d_loss1: {:.3f} d_loss2: {:.3f}\".format(\n",
    "                        epoch+1, n_epoch, step+1, n_step_epoch, time.time() - step_time, mse_loss, vgg_loss, g_gan_loss, d_loss, d_loss1, d_loss2))\n",
    "            g_losses.append(g_loss)\n",
    "            d_losses.append(d_loss)\n",
    "\n",
    "        # save losses to file\n",
    "        with open(g_losses_txt, 'a') as f:\n",
    "            for item in g_losses:\n",
    "                f.write(\"{}\\n\".format(item))\n",
    "                \n",
    "        with open(d_losses_txt, 'a') as f:\n",
    "            for item in d_losses:\n",
    "                f.write(\"{}\\n\".format(item))\n",
    "        \n",
    "        # update the learning rate\n",
    "        if (epoch != 0) and ((epoch+1) % decay_every == 0):\n",
    "            new_lr_decay = lr_decay**((epoch+1) // decay_every)\n",
    "            lr_v.assign(lr_init * new_lr_decay)\n",
    "            log = \" ** new learning rate: %f (for GAN)\" % (lr_init * new_lr_decay)\n",
    "            print(log)\n",
    "\n",
    "        if (epoch != 0) and ((epoch+1) % n_epochs_save_model == 0):\n",
    "            tl.vis.save_images(fake_patchs.numpy(), [2, 4], os.path.join(save_dir, 'train_g_{}.png'.format(epoch+1)))\n",
    "            G.save_weights(os.path.join(checkpoint_dir, 'g_{}.h5'.format(epoch+1)))\n",
    "            D.save_weights(os.path.join(checkpoint_dir, 'd_{}.h5'.format(epoch+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    ###====================== PRE-LOAD DATA ===========================###\n",
    "    # train_hr_img_list = sorted(tl.files.load_file_list(path=config.TRAIN.hr_img_path, regx='.*.png', printable=False))\n",
    "    # train_lr_img_list = sorted(tl.files.load_file_list(path=config.TRAIN.lr_img_path, regx='.*.png', printable=False))\n",
    "    valid_hr_img_list = sorted(tl.files.load_file_list(path=config.VALID.hr_img_path, regx='.*.png', printable=False))\n",
    "    valid_lr_img_list = sorted(tl.files.load_file_list(path=config.VALID.lr_img_path, regx='.*.png', printable=False))\n",
    "\n",
    "    ## if your machine have enough memory, please pre-load the whole train set.\n",
    "    # train_hr_imgs = tl.vis.read_images(train_hr_img_list, path=config.TRAIN.hr_img_path, n_threads=32)\n",
    "    valid_lr_imgs = tl.vis.read_images(valid_lr_img_list, path=config.VALID.lr_img_path, n_threads=32)\n",
    "    valid_hr_imgs = tl.vis.read_images(valid_hr_img_list, path=config.VALID.hr_img_path, n_threads=32)\n",
    "\n",
    "    ###========================== DEFINE MODEL ============================###\n",
    "    imid = 1  # 0: 企鹅  81: 蝴蝶 53: 鸟  64: 古堡\n",
    "    valid_lr_img = valid_lr_imgs[imid]\n",
    "    valid_hr_img = valid_hr_imgs[imid]\n",
    "    # valid_lr_img = get_imgs_fn('test.png', 'data2017/')  # if you want to test your own image\n",
    "    valid_lr_img = (valid_lr_img / 127.5) - 1  # rescale to ［－1, 1]\n",
    "\n",
    "    G = get_G([None, None, 3])\n",
    "    G.load_weights(os.path.join(checkpoint_dir, 'g.h5'))\n",
    "\n",
    "    valid_lr_img = np.asarray(valid_lr_img, dtype=np.float32)\n",
    "    valid_lr_img = valid_lr_img[np.newaxis,:,:,:]\n",
    "    size = [valid_lr_img.shape[1], valid_lr_img.shape[2]]\n",
    "\n",
    "    out = G(valid_lr_img).numpy()\n",
    "\n",
    "    print(\"LR size: %s /  generated HR size: %s\" % (size, out.shape))  # LR size: (339, 510, 3) /  gen HR size: (1, 1356, 2040, 3)\n",
    "    print(\"[*] save images\")\n",
    "    tl.vis.save_image(out[0], os.path.join(save_dir, 'valid_gen.png'))\n",
    "    tl.vis.save_image(valid_lr_img[0], os.path.join(save_dir, 'valid_lr.png'))\n",
    "    tl.vis.save_image(valid_hr_img, os.path.join(save_dir, 'valid_hr.png'))\n",
    "\n",
    "    out_bicu = cv2.resize(valid_lr_img[0], (size[1] * 4, size[0] * 4))\n",
    "    tl.vis.save_image(out_bicu, os.path.join(save_dir, 'valid_bicubic.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_continue():\n",
    "    G = get_G(input_G_shape)\n",
    "    D = get_D(input_D_shape)\n",
    "    G.load_weights(g_trained_dir)\n",
    "    D.load_weights(d_trained_dir)\n",
    "\n",
    "    # Load trained model\n",
    "    json_file = open(os.path.join(checkpoint_dir, 'VGG.json'), 'r')\n",
    "    VGG_json = json_file.read()\n",
    "    json_file.close()\n",
    "    VGG = model_from_json(VGG_json)\n",
    "    VGG.load_weights(os.path.join(checkpoint_dir, 'VGG.h5'))\n",
    "\n",
    "    lr_v = tf.Variable(lr_init)\n",
    "    g_optimizer=tf.optimizers.Adam(lr_v, beta_1=beta1)\n",
    "    d_optimizer=tf.optimizers.Adam(lr_v, beta_1=beta1)\n",
    "\n",
    "    train_ds = get_train_data()\n",
    "    total_images = len(tl.files.load_file_list(path=config.TRAIN.hr_img_path, regx='.*.png', printable=False)[:number_of_images])\n",
    "    n_step_epoch = math.ceil(total_images / batch_size)\n",
    "    \n",
    "    # adversarial learning (G,D)\n",
    "    for epoch in range(n_epoch):\n",
    "        g_losses = []\n",
    "        d_losses = []\n",
    "        for step, (lr_patchs, hr_patchs) in enumerate(train_ds):\n",
    "            step_time = time.time()\n",
    "            # To compute multiple gradients over the same computation, create a persistent gradient tape\n",
    "            with tf.GradientTape(persistent=True) as tape:\n",
    "                fake_patchs = G(lr_patchs)\n",
    "                logits_fake = D(fake_patchs)\n",
    "                logits_real = D(hr_patchs)\n",
    "                feature_fake = VGG((fake_patchs+1)/2.) # the pre-trained VGG uses the input range of [0, 1] but we use input range of [-1 1]\n",
    "                feature_real = VGG((hr_patchs+1)/2.)\n",
    "\n",
    "                d_loss1 = tf.keras.losses.binary_crossentropy(tf.ones_like(logits_real),logits_real, from_logits=True)\n",
    "                d_loss2 = tf.keras.losses.binary_crossentropy(tf.zeros_like(logits_fake),logits_fake,from_logits=True)\n",
    "                d_loss1 = tf.reduce_mean(d_loss1)\n",
    "                d_loss2 = tf.reduce_mean(d_loss2)\n",
    "                d_loss = d_loss1 + d_loss2\n",
    "                g_gan_loss = tf.multiply(tf.constant(1e-3),tf.keras.losses.binary_crossentropy(tf.ones_like(logits_fake),logits_fake,from_logits=True))\n",
    "                g_gan_loss = tf.reduce_mean(g_gan_loss)\n",
    "                mse_loss = tf.keras.losses.mean_squared_error(fake_patchs, hr_patchs)\n",
    "                mse_loss = tf.reduce_mean(mse_loss)\n",
    "                vgg_loss = tf.multiply(tf.constant(2e-6),tf.keras.losses.mean_squared_error(feature_fake, feature_real))\n",
    "                vgg_loss = tf.reduce_mean(vgg_loss)\n",
    "                g_loss = mse_loss + vgg_loss + g_gan_loss\n",
    "            grad = tape.gradient(g_loss, G.trainable_weights)\n",
    "            g_optimizer.apply_gradients(zip(grad, G.trainable_weights))\n",
    "            grad = tape.gradient(d_loss, D.trainable_weights)\n",
    "            d_optimizer.apply_gradients(zip(grad, D.trainable_weights))\n",
    "            if (step == 0) or ((step+1) % verbose == 0):\n",
    "                print(\"Epoch: [{}/{}] step: [{}/{}] time: {:.3f}s, g_loss(mse:{:.3f}, vgg:{:.3f}, adv:{:.3f}) d_loss: {:.3f} d_loss1: {:.3f} d_loss2: {:.3f}\".format(\n",
    "                        epoch+1, n_epoch, step+1, n_step_epoch, time.time() - step_time, mse_loss, vgg_loss, g_gan_loss, d_loss, d_loss1, d_loss2))\n",
    "            g_losses.append(g_loss)\n",
    "            d_losses.append(d_loss)\n",
    "        \n",
    "        # save losses to file\n",
    "        with open(g_losses_txt, 'a') as f:\n",
    "            for item in g_losses:\n",
    "                f.write(\"{}\\n\".format(item))\n",
    "                \n",
    "        with open(d_losses_txt, 'a') as f:\n",
    "            for item in d_losses:\n",
    "                f.write(\"{}\\n\".format(item))\n",
    "            \n",
    "        # update the learning rate\n",
    "        if (epoch != 0) and ((epoch+1) % decay_every == 0):\n",
    "            new_lr_decay = lr_decay**((epoch+1) // decay_every)\n",
    "            lr_v.assign(lr_init * new_lr_decay)\n",
    "            log = \" ** new learning rate: %f (for GAN)\" % (lr_init * new_lr_decay)\n",
    "            print(log)\n",
    "\n",
    "        if (epoch != 0) and ((epoch+1) % n_epochs_save_model == 0):\n",
    "            tl.vis.save_images(fake_patchs.numpy(), [2, 4], os.path.join(save_dir, 'train_g_{}.png'.format(epoch+1)))\n",
    "            G.save_weights(os.path.join(checkpoint_dir, 'g_{}.h5'.format(epoch+1)))\n",
    "            D.save_weights(os.path.join(checkpoint_dir, 'd_{}.h5'.format(epoch+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--mode', type=str, default='srgan', help='srgan, evaluate')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    tl.global_flag['mode'] = args.mode\n",
    "\n",
    "    if tl.global_flag['mode'] == 'srgan':\n",
    "        train()\n",
    "    elif tl.global_flag['mode'] == 'warmup':\n",
    "        warmup()\n",
    "    elif tl.global_flag['mode'] == 'evaluate':\n",
    "        evaluate()\n",
    "    elif tl.global_flag['mode'] == 'continue':\n",
    "        train_continue()\n",
    "    else:\n",
    "        raise Exception(\"Unknow --mode\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
